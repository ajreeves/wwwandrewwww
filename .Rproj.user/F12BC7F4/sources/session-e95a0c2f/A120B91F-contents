#!/usr/bin/env python3
"""
Enhanced bibliography update script that pulls summaries and publisher URLs from BibTeX.
"""

import re
import os

def read_bibtex_file(filename):
    """Read BibTeX file."""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"‚úì Read {len(content)} characters from {filename}")
        return content
    except FileNotFoundError:
        print(f"‚ùå Error: {filename} not found")
        return ""
    except Exception as e:
        print(f"‚ùå Error reading {filename}: {e}")
        return ""

def escape_bibtex(text):
    """Escape BibTeX content for JavaScript."""
    # Handle backslashes first
    text = text.replace('\\', '\\\\')
    # Handle backticks
    text = text.replace('`', '\\`')
    # Handle template literals
    text = text.replace('${', '\\${')
    return text

def extract_summaries_and_urls(bibtex_content):
    """Extract summary and publisher URL fields from BibTeX entries."""
    summaries = {}
    publisher_urls = {}
    
    # Split by @ to find entries
    parts = bibtex_content.split('@')[1:]
    
    for part in parts:
        if not part.strip():
            continue
            
        entry_text = '@' + part
        
        # Find entry key
        first_line = entry_text.split('\n')[0]
        match = re.match(r'@\w+\s*\{\s*([^,\}\s]+)', first_line)
        
        if not match:
            continue
            
        key = match.group(1).strip()
        
        # Skip old format entries with colons
        if ':' in key:
            continue
        
        # Extract summary field using a simpler approach
        # Look for summary = { ... } with proper brace matching
        summary_fields = ['summary', 'abstract', 'note']
        
        for field_name in summary_fields:
            # Find the field start
            field_pattern = rf'{field_name}\s*=\s*\{{'
            field_match = re.search(field_pattern, entry_text, re.IGNORECASE)
            
            if field_match:
                start_pos = field_match.end() - 1  # Position of opening brace
                brace_count = 1
                content_start = start_pos + 1
                pos = content_start
                
                # Find the matching closing brace
                while pos < len(entry_text) and brace_count > 0:
                    if entry_text[pos] == '{':
                        brace_count += 1
                    elif entry_text[pos] == '}':
                        brace_count -= 1
                    pos += 1
                
                if brace_count == 0:
                    summary = entry_text[content_start:pos-1].strip()
                    # Clean up HTML tags and extra whitespace
                    summary = re.sub(r'<[^>]+>', '', summary)  # Remove HTML tags
                    summary = re.sub(r'\\[a-zA-Z]+\{([^}]*)\}', r'\1', summary)  # Remove LaTeX commands
                    summary = re.sub(r'\s+', ' ', summary)  # Normalize whitespace
                    summary = summary.strip()
                    if summary:  # Only add if not empty
                        summaries[key] = summary
                        print(f"   Found summary for {key}: {summary[:60]}...")
                    break
        
        # Extract URL fields using simple regex
        url_fields = ['url', 'publisherurl', 'publisher-url', 'journal-url', 'journalurl', 'bdsk-url-1']
        
        for field_name in url_fields:
            url_pattern = rf'{field_name}\s*=\s*\{{([^}}]+)\}}'
            url_match = re.search(url_pattern, entry_text, re.IGNORECASE)
            if url_match:
                url = url_match.group(1).strip()
                # Skip PDF and archive URLs for publisher links
                if not any(skip in url.lower() for skip in ['pdf', 'archive', 'wayback']):
                    publisher_urls[key] = url
                    print(f"   Found URL for {key}: {url}")
                break
    
    print(f"‚úì Extracted {len(summaries)} summaries and {len(publisher_urls)} publisher URLs")
    return summaries, publisher_urls

def generate_summaries_js(summaries):
    """Generate JavaScript object for summaries."""
    if not summaries:
        return "const summaries = {};"
    
    js_lines = ["const summaries = {"]
    
    for key, summary in summaries.items():
        # Escape quotes and newlines for JavaScript
        escaped_summary = summary.replace('\\', '\\\\').replace("'", "\\'").replace('"', '\\"').replace('\n', ' ')
        js_lines.append(f"  '{key}': '{escaped_summary}',")
    
    js_lines.append("};")
    
    result = '\n'.join(js_lines)
    print(f"‚úì Generated summaries JavaScript ({len(result)} characters)")
    return result

def generate_publisher_urls_js(publisher_urls):
    """Generate JavaScript object for publisher URLs."""
    if not publisher_urls:
        return "const publisherUrls = {};"
    
    js_lines = ["const publisherUrls = {"]
    
    for key, url in publisher_urls.items():
        # Escape quotes for JavaScript
        escaped_url = url.replace('\\', '\\\\').replace("'", "\\'").replace('"', '\\"')
        js_lines.append(f"  '{key}': '{escaped_url}',")
    
    js_lines.append("};")
    
    result = '\n'.join(js_lines)
    print(f"‚úì Generated publisher URLs JavaScript ({len(result)} characters)")
    return result

def update_research_file(input_file, output_file, bibtex_file):
    """Update the research file with BibTeX data and extracted metadata."""
    
    # Read BibTeX file
    bibtex_content = read_bibtex_file(bibtex_file)
    if not bibtex_content:
        print("‚ùå Failed to read BibTeX file")
        return False
    
    # Extract summaries and publisher URLs
    summaries, publisher_urls = extract_summaries_and_urls(bibtex_content)
    
    # Read template file
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"‚úì Read template file: {input_file}")
    except Exception as e:
        print(f"‚ùå Error reading {input_file}: {e}")
        return False
    
    # Escape BibTeX content
    escaped_bibtex = escape_bibtex(bibtex_content)
    
    # Replace BibTeX data placeholder
    placeholder_pattern = r'const bibData = `[^`]*`;'
    replacement = f'const bibData = `{escaped_bibtex}`;'
    
    if re.search(placeholder_pattern, content):
        content = re.sub(placeholder_pattern, replacement, content, flags=re.DOTALL)
        print(f"‚úì Updated bibData with {len(bibtex_content):,} characters")
    else:
        print("‚ö†Ô∏è  Could not find bibData placeholder")
        return False
    
    # Insert summaries and publisher URLs after the bibData line
    summaries_js = generate_summaries_js(summaries)
    publisher_urls_js = generate_publisher_urls_js(publisher_urls)
    
    # Find the exact bibData line that was just inserted and add content after it
    bibdata_line = f'const bibData = `{escaped_bibtex}`;'
    bibdata_pos = content.find(bibdata_line)
    
    if bibdata_pos != -1:
        # Find the end of this line
        end_pos = bibdata_pos + len(bibdata_line)
        
        # Insert both summaries and publisher URLs right after the bibData line
        insertion = f'\n\n{summaries_js}\n\n{publisher_urls_js}'
        content = content[:end_pos] + insertion + content[end_pos:]
        print("‚úì Added summaries and publisher URLs data")
    else:
        print("‚ö†Ô∏è  Could not find bibData line to insert after")
        print("Trying alternative approach...")
        
        # Alternative: just append before the first function
        script_start = content.find('function parseBibTeX')
        if script_start != -1:
            insertion = f'\n{summaries_js}\n\n{publisher_urls_js}\n\n'
            content = content[:script_start] + insertion + content[script_start:]
            print("‚úì Added summaries and URLs using alternative method")
        else:
            print("‚ö†Ô∏è  Could not find any insertion point")
            return False
    
    # Write output file
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"‚úì Successfully wrote to {output_file}")
        return True
    except Exception as e:
        print(f"‚ùå Error writing to {output_file}: {e}")
        return False

def main():
    """Main function."""
    
    input_file = "makeresearch.qmd"
    output_file = "research.qmd"
    bibtex_file = "references.bib"
    
    print("üîÑ Enhanced Bibliography Update")
    print("=" * 45)
    print(f"Template: {input_file}")
    print(f"Output: {output_file}")
    print(f"BibTeX: {bibtex_file}")
    print("-" * 45)
    
    # Check files exist
    missing_files = []
    for filename in [input_file, bibtex_file]:
        if not os.path.exists(filename):
            missing_files.append(filename)
    
    if missing_files:
        print(f"‚ùå Missing files: {', '.join(missing_files)}")
        print("\nüí° To add summaries to your publications:")
        print("   Add 'summary = {Your summary text}' to BibTeX entries")
        print("   Add 'publisherurl = {https://...}' for publisher links")
        print("   You can also use 'abstract', 'note', or 'url' fields")
        return
    
    # Update file
    success = update_research_file(input_file, output_file, bibtex_file)
    
    print("-" * 45)
    if success:
        print("‚úÖ Enhanced update completed successfully!")
        print("üìÑ Features enabled:")
        print("   ‚Ä¢ Dynamic summaries from BibTeX")
        print("   ‚Ä¢ Publisher URLs from BibTeX")
        print("   ‚Ä¢ Automatic field extraction")
        print(f"üìñ Check {output_file} for your publications")
    else:
        print("‚ùå Update failed")

if __name__ == "__main__":
    main()
